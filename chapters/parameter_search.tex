In order to obtain optimal performance from the neural networks
given a set of atomistic configurations we need a careful choice of parameters
and neural network architecture. The parameters can be classified as either
training parameters - such as learning rate and force loss coefficient -
or architectural parameters - such as the number of neurons and hidden layers,
or the choice of interaction cutoff radius. The former are important
in the training of the neural network, i.e. adjusting weights and biases
while the latter influence both the training process and the final
deployment of the neural networks on unfamiliar data.
In this section we will be employing a grid search over a set of
parameters, training multiple neural networks on the same data set
and subsequently testing energy and force Root Mean Squared Errors on
a smaller test data set. Generally we will only be training the neural networks
on the energies, since training with forces is much more CPU- and memory-
intensive. However, training with forces would likely affect the final
result and improve the force RMSEs, as we will observe in the following section.
The parameters are unless otherwise specified the defaults listed
in table \ref{table:defaults}.
In their paper on Random Search, \parencite[Bergstra and Bengio]{
    bergstra2012random}
demonstrate that Random Search outperforms Grid Search for dimensions
of search space larger than 3 or 4. However, since we have tested
a small number of parameters (since training and testing is costly)
and we have a general idea of what parameters are appropriate, we
have chosen to employ Grid Search.

\begin{table}[h]
\begin{tabular}{@{}lll@{}}
\toprule
\multicolumn{3}{l}{Hyperparameters}                                    \\ \midrule
Architecture & Symmetry functions & 4 radial, 8 angular                \\
             & Hidden layers      & (10, 10)                           \\
             & Activation         & Hyperbolic tangent                 \\
             & Cutoff function    & Polynomial, $R_c = 5.0$            \\
Training     & Epochs             & 500                               \\
             & Energy coefficient & 1.0                                \\
             & Force coefficient  & None                                \\
             & Optimizer          & BFGS                               \\ \bottomrule
\end{tabular}
\caption{Training defaults}
\label{table:defaults}
\end{table}

For the symmetry functions we have chosen a set of 4 radial and 8 angular (G5)
symmetry functions. The radial functions are centered evenly from
0.5 to $R_c + 0.5$ with $\eta = 10$ and the angular functions
are centered at 0 with $\eta s$ logarithmically spaced from 0.1 to 1.0,
$\gamma = \pm 1$ and $\zeta = 1$.

\begin{figure}[!tbp]
\begin{adjustbox}{max width=1.2\linewidth,center}
\centering
  \begin{subfigure}[b]{0.55\textwidth}
      \includegraphics[width=\textwidth]{radial_centered.png}
    \caption{Flower one.}
    \label{fig:f1}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.55\textwidth}
      \includegraphics[width=\textwidth]{angular_centered.png}
    \caption{Flower two.}
    \label{fig:f2}
  \end{subfigure}
\end{adjustbox}
\caption{My flowers.}
\end{figure}



\subsection{Force training}
When training the neural networks we have the choice of whether
to incorporate the forces into our loss function, or only fit
the neural network to the potential energy. By default, unless
we have access to a per-atom energy every configuration is labeled
with only a single number for a potentially large number of atoms,
which limits the improvement in loss metrics for every epoch
and the final result. If instead we incorporate the forces into the
loss we have potentially $3N + 1$ labels for every epoch,
which provides a lot more information for weight updates.
In the previous chapter we also showed how adding derivatives to
the loss function could significantly improve the accuracy of the
derivatives. Since the forces determine the trajectories generated
from molecular dynamics we would expect we would expect much better
accuracy and numerical stability if we could improve the fit of
the derivatives.
The real drawback is the calculation of the derivatives in the input layer,
aka the fingerprintprimes, of which there are a lot for every coordinate
and input symmetry function, and they consume a lot of disk space and memory.
\par
In order to test these hypotheses we test the performance of neural networks
trained with and without forces on a set of test images.
A system of copper atoms is generated in the face-centered cubic (FCC)
configuration with 4 atoms in the unit cell and $3 \times 3 \times 3$
unit cells for a total of $4 \cdot 3^3 = 108$ atoms. The
atoms are given velocities from the Maxwell-Boltzmann distribution
corresponding to a temperature of 500 Kelvin. The potential we will
be using is the Effective Medium Theory (EMT), which has a very
fast Fortran implementation in the ASE software package\footnote{
\url{https://wiki.fysik.dtu.dk/asap/asap}}.
The training trajectory is ran for $2 \cdot 10^4$ steps with
a timestep of $\Delta t = 1$fs and written to file every 100 steps
for a total of 200 atomic configurations. The test trajectory is
integrated for $7.5 \cdot 10^3$ steps for a total of 75 atomic configurations.
In table \ref{table:defaults} we have listed the default parameters
used in the training and testing of the neural network:


\begin{figure}[!tbp]
\begin{adjustbox}{max width=1.2\linewidth,center}
\centering
  \begin{subfigure}[b]{0.55\textwidth}
      \includegraphics[width=\textwidth]{energy_noforcetrain.png}
    \caption{Flower one.}
    \label{fig:f1}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.55\textwidth}
      \includegraphics[width=\textwidth]{force_noforcetrain.png}
    \caption{Flower two.}
    \label{fig:f2}
  \end{subfigure}
\end{adjustbox}
\caption{My flowers.}
\end{figure}

\begin{figure}[!tbp]
\begin{adjustbox}{max width=1.2\linewidth,center}
\centering
  \begin{subfigure}[b]{0.55\textwidth}
      \includegraphics[width=\textwidth]{energy_forcetrain.png}
    \caption{Flower one.}
    \label{fig:f1}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.55\textwidth}
      \includegraphics[width=\textwidth]{force_forcetrain.png}
    \caption{Flower two.}
    \label{fig:f2}
  \end{subfigure}
\end{adjustbox}
\caption{My flowers.}
\end{figure}


\subsection{Activation, hidden layers}

\begin{tabular}{lrr}
\toprule
Activation/Hidden layers &  Energy RMSE &  Force RMSE \\
\midrule
               tanh-[10] &     2.13E-02 &    9.22E+00 \\
               tanh-[20] &     2.77E-02 &    3.71E+00 \\
               tanh-[30] &     2.25E-02 &    7.58E+00 \\
               tanh-[40] &     2.55E-02 &    6.65E+00 \\
           tanh-[10, 10] &     3.13E-02 &    8.69E-01 \\
           tanh-[20, 10] &     2.87E-02 &    2.96E+00 \\
           tanh-[30, 10] &     3.12E-02 &    2.29E+00 \\
           tanh-[40, 40] &     2.38E-02 &    7.87E+00 \\
            sigmoid-[10] &     3.07E-02 &    3.01E+00 \\
            sigmoid-[20] &     3.62E-02 &    5.87E-01 \\
            sigmoid-[30] &     1.65E-02 &    1.96E+01 \\
            sigmoid-[40] &     3.06E-02 &    2.82E+00 \\
        sigmoid-[10, 10] &     2.83E-02 &    3.62E+00 \\
        sigmoid-[20, 10] &     3.07E-02 &    1.57E+00 \\
        sigmoid-[30, 10] &     2.89E-02 &    4.30E+00 \\
        sigmoid-[40, 40] &     2.63E-02 &    6.23E+00 \\
\bottomrule
\end{tabular}

\subsection{Cutoff radius}

\begin{tabular}{lrr}
\toprule
         Cutoff &  Energy RMSE &  Force RMSE \\
\midrule
     Cosine-3.0 &     2.36E-03 &    3.80E-01 \\
 Polynomial-3.0 &     9.71E+00 &    3.50E-01 \\
     Cosine-4.0 &     1.94E+01 &    4.21E-01 \\
 Polynomial-4.0 &     2.41E+01 &    4.13E-01 \\
     Cosine-5.0 &     5.60E+01 &    4.03E-01 \\
 Polynomial-5.0 &     9.44E+01 &    4.03E-01 \\
     Cosine-6.0 &     3.71E+01 &    4.03E-01 \\
 Polynomial-6.0 &     1.11E+02 &    4.03E-01 \\
     Cosine-7.0 &     8.33E+01 &    4.03E-01 \\
 Polynomial-7.0 &     4.31E+02 &    4.03E-01 \\
\bottomrule
\end{tabular}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{copper_rdf.png}
    \caption{Copper RDF}
    \label{fig:copper_rdf}
\end{figure}

\subsection{Symmetry functions}

\begin{figure}[!tbp]
\begin{adjustbox}{max width=1.2\linewidth,center}
\centering
  \begin{subfigure}[b]{0.55\textwidth}
      \includegraphics[width=\textwidth]{radial_uncentered.png}
    \caption{Flower one.}
    \label{fig:f1}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.55\textwidth}
      \includegraphics[width=\textwidth]{angular_uncentered.png}
    \caption{Flower two.}
    \label{fig:f2}
  \end{subfigure}
\end{adjustbox}
\caption{My flowers.}
\end{figure}

\begin{tabular}{lrr}
\toprule
    Symmetry function &  Energy RMSE &  Force RMSE \\
\midrule
              Default &     8.08E-03 &    2.75E+01 \\
 Gs-4-1-G4-uncentered &     2.25E-02 &    1.32E+00 \\
 Gs-4-1-G5-uncentered &     2.40E-02 &    1.46E+00 \\
   Gs-4-1-G4-centered &     1.24E-02 &    2.07E+01 \\
   Gs-4-1-G5-centered &     8.95E-03 &    2.36E+01 \\
 Gs-5-1-G4-uncentered &     2.41E-02 &    1.82E+00 \\
 Gs-5-1-G5-uncentered &     2.44E-02 &    3.24E-01 \\
   Gs-5-1-G4-centered &     2.35E-02 &    3.57E+00 \\
   Gs-5-1-G5-centered &     8.96E-03 &    2.76E+01 \\
 Gs-6-1-G4-uncentered &     9.13E-03 &    2.68E+01 \\
 Gs-6-1-G5-uncentered &     1.13E-02 &    1.95E+01 \\
   Gs-6-1-G4-centered &     2.05E-02 &    7.47E+00 \\
   Gs-6-1-G5-centered &     1.02E-02 &    2.59E+01 \\
 Gs-7-1-G4-uncentered &     1.63E-02 &    2.05E+01 \\
 Gs-7-1-G5-uncentered &     8.54E-03 &    2.61E+01 \\
   Gs-7-1-G4-centered &     9.91E-03 &    2.29E+01 \\
   Gs-7-1-G5-centered &     9.17E-03 &    2.75E+01 \\
 Gs-8-2-G4-uncentered &     2.36E-02 &    9.57E+00 \\
 Gs-8-2-G5-uncentered &     1.50E-02 &    1.71E+01 \\
   Gs-8-2-G4-centered &     2.30E-02 &    1.79E+00 \\
   Gs-8-2-G5-centered &     8.75E-03 &    2.48E+01 \\
\bottomrule
\end{tabular}

\subsection{Sampling and scaling}

\begin{tabular}{lrr}
\toprule
Number of images &  Energy RMSE &  Force RMSE \\
\midrule
             n10 &     1.16E-01 &    5.94E-01 \\
             n20 &     7.16E-02 &    3.83E-01 \\
             n50 &     3.02E-02 &    5.03E-01 \\
            n100 &     2.55E-02 &    2.61E-01 \\
            n200 &     7.53E-03 &    1.60E-01 \\
            n500 &     9.26E-03 &    3.02E-01 \\
           n1000 &     7.57E-03 &    1.34E-01 \\
           n2000 &     8.22E-03 &    1.33E-01 \\
           n5000 &     7.41E-03 &    4.17E-01 \\
\bottomrule
\end{tabular}
